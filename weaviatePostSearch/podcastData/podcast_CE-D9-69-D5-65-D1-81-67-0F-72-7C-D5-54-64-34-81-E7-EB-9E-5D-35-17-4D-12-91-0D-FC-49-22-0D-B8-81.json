{
    "Id": "CE-D9-69-D5-65-D1-81-67-0F-72-7C-D5-54-64-34-81-E7-EB-9E-5D-35-17-4D-12-91-0D-FC-49-22-0D-B8-81",
    "ContentSourceId": "03e85e81-f3bb-4c2c-944d-b6722870407b",
    "Title": "684: Get More Language Context out of your LLM",
    "SourceUrl": "https://www.podtrac.com/pts/redirect.mp3/chrt.fm/track/E581B9/arttrk.com/p/VI4CS/pscrb.fm/rss/p/traffic.megaphone.fm/SUPERDATASCIENCEPTYLTD8305933044.mp3?updated=1716819079",
    "Description": "\n        <p>Open-source LLMs, FlashAttention and generative AI terminology: Host Jon Krohn gives us the lift we need to explore the next big steps in generative AI. Listen to the specific way in which Stanford University\u2019s \u201cexact attention\u201d algorithm, FlashAttention, could become a competitor for GPT-4\u2019s capabilities.<br><br>Additional materials: <a href=\"https://www.superdatascience.com/684\">www.superdatascience.com/684</a><br><br>Interested in sponsoring a SuperDataScience Podcast episode? Visit <a href=\"https://www.jonkrohn.com/podcast\">JonKrohn.com/podcast</a> for sponsorship information.</p>\n      ",
    "EnclosureUrl": "https://www.podtrac.com/pts/redirect.mp3/chrt.fm/track/E581B9/arttrk.com/p/VI4CS/pscrb.fm/rss/p/traffic.megaphone.fm/SUPERDATASCIENCEPTYLTD8305933044.mp3?updated=1716819079"
}