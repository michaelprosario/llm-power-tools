{
    "Id": "D3-E1-50-3F-13-84-5F-CD-90-FA-DF-79-1A-89-B4-B6-E1-87-89-EC-16-9D-48-05-53-A4-84-DB-88-56-70-92",
    "ContentSourceId": "03e85e81-f3bb-4c2c-944d-b6722870407b",
    "Title": "771: Gradient Boosting: XGBoost, LightGBM and CatBoost, with Kirill Eremenko",
    "SourceUrl": "https://www.podtrac.com/pts/redirect.mp3/chrt.fm/track/E581B9/arttrk.com/p/VI4CS/pscrb.fm/rss/p/traffic.megaphone.fm/SUPERDATASCIENCEPTYLTD5316074885.mp3?updated=1716818956",
    "Description": "\n        <p>Kirill Eremenko joins Jon Krohn for another exclusive, in-depth teaser for a new course just released on the SuperDataScience platform, \u201cMachine Learning Level 2\u201d. Kirill walks listeners through why decision trees and random forests are fruitful for businesses, and he offers hands-on walkthroughs for the three leading gradient-boosting algorithms today: XGBoost, LightGBM, and CatBoost.<br><br>This episode is brought to you by <a href=\"https://www.readytensor.ai/\">Ready Tensor</a>, where innovation meets reproducibility, and by <a href=\"https://datauniverse2024.com/\">Data Universe</a>, the out-of-this-world data conference. Interested in sponsoring a SuperDataScience Podcast episode? Visit <a href=\"https://passionfroot.me/superdatascience\">passionfroot.me/superdatascience</a> for sponsorship information.<br><br>In this episode you will learn:<br>\u2022 All about decision trees [09:17]<br>\u2022 All about ensemble models [21:43]<br>\u2022 All about AdaBoost [36:47]<br>\u2022 All about gradient boosting [45:52]<br>\u2022 Gradient boosting for classification problems [59:54]<br>\u2022 Advantages of XGBoost [1:03:51]<br>\u2022 LightGBM [1:17:06]<br>\u2022 CatBoost [1:32:07]<br><br>Additional materials: <a href=\"https://www.superdatascience.com/771\">www.superdatascience.com/771</a></p>\n      ",
    "EnclosureUrl": "https://www.podtrac.com/pts/redirect.mp3/chrt.fm/track/E581B9/arttrk.com/p/VI4CS/pscrb.fm/rss/p/traffic.megaphone.fm/SUPERDATASCIENCEPTYLTD5316074885.mp3?updated=1716818956"
}