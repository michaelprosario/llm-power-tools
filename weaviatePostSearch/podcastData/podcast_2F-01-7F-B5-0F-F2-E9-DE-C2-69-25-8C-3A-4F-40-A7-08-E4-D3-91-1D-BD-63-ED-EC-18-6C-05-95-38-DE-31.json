{
    "Id": "2F-01-7F-B5-0F-F2-E9-DE-C2-69-25-8C-3A-4F-40-A7-08-E4-D3-91-1D-BD-63-ED-EC-18-6C-05-95-38-DE-31",
    "ContentSourceId": "08ddc66c-88c1-4fd9-9d0f-06779ee4a5cb",
    "Title": "#103 - Prof. Edward Grefenstette - Language, Semantics, Philosophy",
    "SourceUrl": "https://podcasters.spotify.com/pod/show/machinelearningstreettalk/episodes/103---Prof--Edward-Grefenstette---Language--Semantics--Philosophy-e1uqlsv",
    "Description": "<p>Support us! https://www.patreon.com/mlst&nbsp;</p>\n<p>MLST Discord: https://discord.gg/aNPkGUQtc5</p>\n<p>YT: https://youtu.be/i9VPPmQn9HQ</p>\n<p><br></p>\n<p>Edward Grefenstette is a Franco-American computer scientist who currently serves as Head of Machine Learning at Cohere and Honorary Professor at UCL. He has previously been a research scientist at Facebook AI Research and staff research scientist at DeepMind, and was also the CTO of Dark Blue Labs. Prior to his move to industry, Edward was a Fulford Junior Research Fellow at Somerville College, University of Oxford, and was lecturing at Hertford College. He obtained his BSc in Physics and Philosophy from the University of Sheffield and did graduate work in the philosophy departments at the University of St Andrews. His research draws on topics and methods from Machine Learning, Computational Linguistics and Quantum Information Theory, and has done work implementing and evaluating compositional vector-based models of natural language semantics and empirical semantic knowledge discovery.</p>\n<p><br></p>\n<p>https://www.egrefen.com/</p>\n<p>https://cohere.ai/</p>\n<p><br></p>\n<p>TOC:</p>\n<p>[00:00:00] Introduction</p>\n<p>[00:02:52] Differential Semantics</p>\n<p>[00:06:56] Concepts</p>\n<p>[00:10:20] Ontology</p>\n<p>[00:14:02] Pragmatics</p>\n<p>[00:16:55] Code helps with language</p>\n<p>[00:19:02] Montague</p>\n<p>[00:22:13] RLHF</p>\n<p>[00:31:54] Swiss cheese problem / retrieval augmented</p>\n<p>[00:37:06] Intelligence / Agency</p>\n<p>[00:43:33] Creativity</p>\n<p>[00:46:41] Common sense</p>\n<p>[00:53:46] Thinking vs knowing</p>\n<p><br></p>\n<p><br></p>\n<p>References:</p>\n<p><br></p>\n<p>Large language models are not zero-shot communicators (Laura Ruis)</p>\n<p>https://arxiv.org/abs/2210.14986</p>\n<p><br></p>\n<p>Some remarks on Large Language Models (Yoav Goldberg)</p>\n<p>https://gist.github.com/yoavg/59d174608e92e845c8994ac2e234c8a9</p>\n<p><br></p>\n<p>Quantum Natural Language Processing (Bob Coecke)</p>\n<p>https://www.cs.ox.ac.uk/people/bob.coecke/QNLP-ACT.pdf</p>\n<p><br></p>\n<p>Constitutional AI: Harmlessness from AI Feedback</p>\n<p>https://www.anthropic.com/constitutional.pdf</p>\n<p><br></p>\n<p>Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks (Patrick Lewis)</p>\n<p>https://www.patricklewis.io/publication/rag/</p>\n<p><br></p>\n<p>Natural General Intelligence (Prof. Christopher Summerfield)</p>\n<p>https://global.oup.com/academic/product/natural-general-intelligence-9780192843883</p>\n<p><br></p>\n<p>ChatGPT with Rob Miles - Computerphile</p>\n<p>https://www.youtube.com/watch?v=viJt_DXTfwA</p>\n",
    "EnclosureUrl": "https://anchor.fm/s/1e4a0eac/podcast/play/64886111/https%3A%2F%2Fd3ctxlq1ktw2nl.cloudfront.net%2Fstaging%2F2023-1-11%2F4c4a3c7e-b852-53d6-bd24-925cc62046b2.mp3"
}