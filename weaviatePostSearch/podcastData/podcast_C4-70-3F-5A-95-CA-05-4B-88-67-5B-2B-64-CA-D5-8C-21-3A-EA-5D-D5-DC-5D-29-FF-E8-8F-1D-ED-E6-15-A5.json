{
    "Id": "C4-70-3F-5A-95-CA-05-4B-88-67-5B-2B-64-CA-D5-8C-21-3A-EA-5D-D5-DC-5D-29-FF-E8-8F-1D-ED-E6-15-A5",
    "ContentSourceId": "08ddc66c-88c1-4fd9-9d0f-06779ee4a5cb",
    "Title": "#55 Self-Supervised Vision Models (Dr. Ishan Misra - FAIR).",
    "SourceUrl": "https://podcasters.spotify.com/pod/show/machinelearningstreettalk/episodes/55-Self-Supervised-Vision-Models-Dr--Ishan-Misra---FAIR-e1355js",
    "Description": "<p>Dr. Ishan Misra is a Research Scientist at Facebook AI Research where he works on Computer Vision and Machine Learning. His main research interest is reducing the need for human supervision, and indeed, human knowledge in visual learning systems. He finished his PhD at the Robotics Institute at Carnegie Mellon. He has done stints at Microsoft Research, INRIA and Yale. His bachelors is in computer science where he achieved the highest GPA in his cohort.&nbsp;</p>\n<p><br></p>\n<p>Ishan is fast becoming a prolific scientist, already with more than 3000 citations under his belt and co-authoring with Yann LeCun; the godfather of deep learning. &nbsp;Today though we will be focusing an exciting cluster of recent papers around unsupervised representation learning for computer vision released from FAIR. These are; DINO: Emerging Properties in Self-Supervised Vision Transformers, BARLOW TWINS: Self-Supervised Learning via Redundancy Reduction and PAWS: Semi-Supervised Learning of Visual Features by Non-Parametrically Predicting View Assignments with</p>\n<p>Support Samples. All of these papers are hot off the press, just being officially released in the last month or so. Many of you will remember PIRL: Self-Supervised Learning of Pretext-Invariant Representations which Ishan was the primary author of in 2019.</p>\n<p><br></p>\n<p>References;</p>\n<p><br></p>\n<p>Shuffle and Learn - https://arxiv.org/abs/1603.08561</p>\n<p>DepthContrast - https://arxiv.org/abs/2101.02691</p>\n<p>DINO - https://arxiv.org/abs/2104.14294</p>\n<p>Barlow Twins - https://arxiv.org/abs/2103.03230</p>\n<p>SwAV - https://arxiv.org/abs/2006.09882</p>\n<p>PIRL - https://arxiv.org/abs/1912.01991</p>\n<p>AVID - https://arxiv.org/abs/2004.12943 (best paper candidate at CVPR'21 (just announced over the weekend) - http://cvpr2021.thecvf.com/node/290)</p>\n<p>&nbsp;</p>\n<p>Alexei (Alyosha) Efros</p>\n<p>http://people.eecs.berkeley.edu/~efros/</p>\n<p>http://www.cs.cmu.edu/~tmalisie/projects/nips09/</p>\n<p>&nbsp;</p>\n<p>Exemplar networks</p>\n<p>https://arxiv.org/abs/1406.6909</p>\n<p>&nbsp;</p>\n<p>The bitter lesson - Rich Sutton</p>\n<p>http://www.incompleteideas.net/IncIdeas/BitterLesson.html</p>\n<p>&nbsp;</p>\n<p>Machine Teaching: A New Paradigm for Building Machine Learning Systems</p>\n<p>https://arxiv.org/abs/1707.06742</p>\n<p>&nbsp;</p>\n<p>POET</p>\n<p>https://arxiv.org/pdf/1901.01753.pdf</p>\n",
    "EnclosureUrl": "https://anchor.fm/s/1e4a0eac/podcast/play/35869756/https%3A%2F%2Fd3ctxlq1ktw2nl.cloudfront.net%2Fstaging%2F2021-5-21%2F6f9782df-d4f0-9fa1-1fe8-b04a7444e7d1.mp3"
}