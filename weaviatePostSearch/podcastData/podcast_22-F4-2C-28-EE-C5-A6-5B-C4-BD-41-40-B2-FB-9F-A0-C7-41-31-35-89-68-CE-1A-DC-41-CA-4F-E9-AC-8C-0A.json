{
    "Id": "22-F4-2C-28-EE-C5-A6-5B-C4-BD-41-40-B2-FB-9F-A0-C7-41-31-35-89-68-CE-1A-DC-41-CA-4F-E9-AC-8C-0A",
    "ContentSourceId": "08ddc66c-88c1-4fd9-9d0f-06779ee4a5cb",
    "Title": "STEPHEN WOLFRAM 2.0 - Resolving the Mystery of the Second Law of Thermodynamics",
    "SourceUrl": "https://podcasters.spotify.com/pod/show/machinelearningstreettalk/episodes/STEPHEN-WOLFRAM-2-0---Resolving-the-Mystery-of-the-Second-Law-of-Thermodynamics-e2847qh",
    "Description": "<p>Please check out Numerai - our sponsor @\nhttp://numer.ai/mlst\n\nPatreon: https://www.patreon.com/mlst\nDiscord: https://discord.gg/ESrGqhf5CB\n\nThe Second Law: Resolving the Mystery of the Second Law of Thermodynamics\nBuy Stephen&#39;s book here - https://tinyurl.com/2jj2t9wa\n\nThe Language Game: How Improvisation Created Language and Changed the World by Morten H. Christiansen and Nick Chater\nBuy here: https://tinyurl.com/35bvs8be \n\nStephen Wolfram starts by discussing the second law of thermodynamics - the idea that entropy, or disorder, tends to increase over time. He talks about how this law seems intuitively true, but has been difficult to prove. Wolfram outlines his decades-long quest to fully understand the second law, including failed early attempts to simulate particles mixing as a 12-year-old. He explains how irreversibility arises from the computational irreducibility of underlying physical processes coupled with our limited ability as observers to do the computations needed to &quot;decrypt&quot; the microscopic details.\n\nThe conversation then shifts to discussing language and how concepts allow us to communicate shared ideas between minds positioned in different parts of &quot;rule space.&quot; Wolfram talks about the successes and limitations of using large language models to generate Wolfram Language code from natural language prompts. He sees it as a useful tool for getting started programming, but one still needs human refinement.\n\nThe final part of the conversation focuses on AI safety and governance. Wolfram notes uncontrolled actuation is where things can go wrong with AI systems. He discusses whether AI agents could have intrinsic experiences and goals, how we might build trust networks between AIs, and that managing a system of many AIs may be easier than a single AI. Wolfram emphasizes the need for more philosophical depth in thinking about AI aims, and draws connections between potential solutions and his work on computational irreducibility and physics.\n\nShow notes: https://docs.google.com/document/d/1hXNHtvv8KDR7PxCfMh9xOiDFhU3SVDW8ijyxeTq9LHo/edit?usp=sharing\nPod version: TBA\n\nhttps://twitter.com/stephen_wolfram\n\nTOC:\n00:00:00 - Introduction\n00:02:34 - Second law book\n00:14:01 - Reversibility / entropy / observers / equivalence\n00:34:22 - Concepts/language in the ruliad\n00:49:04 - Comparison to free energy principle\n00:53:58 - ChatGPT / Wolfram / Language\n01:00:17 - AI risk\n\nPanel: Dr. Tim Scarfe @ecsquendor / Dr. Keith Duggar @DoctorDuggar</p>\n",
    "EnclosureUrl": "https://anchor.fm/s/1e4a0eac/podcast/play/74636561/https%3A%2F%2Fd3ctxlq1ktw2nl.cloudfront.net%2Fstaging%2F2023-7-15%2F10889ed6-9b45-bf9b-712a-f509dddb0716.mp3"
}