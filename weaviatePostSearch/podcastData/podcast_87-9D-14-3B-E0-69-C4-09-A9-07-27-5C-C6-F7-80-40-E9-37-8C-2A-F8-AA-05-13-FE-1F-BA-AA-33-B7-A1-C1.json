{
    "Id": "87-9D-14-3B-E0-69-C4-09-A9-07-27-5C-C6-F7-80-40-E9-37-8C-2A-F8-AA-05-13-FE-1F-BA-AA-33-B7-A1-C1",
    "ContentSourceId": "08ddc66c-88c1-4fd9-9d0f-06779ee4a5cb",
    "Title": "Prof. J\u00fcrgen Schmidhuber - FATHER OF AI ON ITS DANGERS",
    "SourceUrl": "https://podcasters.spotify.com/pod/show/machinelearningstreettalk/episodes/Prof--Jrgen-Schmidhuber---FATHER-OF-AI-ON-ITS-DANGERS-e2839av",
    "Description": "<p>Please check out Numerai - our sponsor @\nhttp://numer.ai/mlst\n\nPatreon: https://www.patreon.com/mlst\nDiscord: https://discord.gg/ESrGqhf5CB\n\nProfessor J\u00fcrgen Schmidhuber, the father of artificial intelligence, joins us today. Schmidhuber discussed the history of machine learning, the current state of AI, and his career researching recursive self-improvement, artificial general intelligence and its risks. \n\nSchmidhuber pointed out the importance of studying the history of machine learning to properly assign credit for key breakthroughs. He discussed some of the earliest machine learning algorithms. He also highlighted the foundational work of Leibniz, who discovered the chain rule that enables training of deep neural networks, and the ancient Antikythera mechanism, the first known gear-based computer. \n\nSchmidhuber discussed limits to recursive self-improvement and artificial general intelligence, including physical constraints like the speed of light and what can be computed. He noted we have no evidence the human brain can do more than traditional computing. Schmidhuber sees humankind as a potential stepping stone to more advanced, spacefaring machine life which may have little interest in humanity. However, he believes commercial incentives point AGI development towards being beneficial and that open-source innovation can help to achieve &quot;AI for all&quot; symbolised by his company&#39;s motto &quot;AI\u2200&quot;.\n\nSchmidhuber discussed approaches he believes will lead to more general AI, including meta-learning, reinforcement learning, building predictive world models, and curiosity-driven learning. His &quot;fast weight programming&quot; approach from the 1990s involved one network altering another network&#39;s connections. This was actually the first Transformer variant, now called an unnormalised linear Transformer. He also described the first GANs in 1990, to implement artificial curiosity.\n\nSchmidhuber reflected on his career researching AI. He said his fondest memories were gaining insights that seemed to solve longstanding problems, though new challenges always arose: &quot;then for a brief moment it looks like the greatest thing since sliced bread and and then you get excited ... but then suddenly you realize, oh, it&#39;s still not finished. Something important is missing.\u201d Since 1985 he has worked on systems that can recursively improve themselves, constrained only by the limits of physics and computability. He believes continual progress, shaped by both competition and collaboration, will lead to increasingly advanced AI. \n\nOn AI Risk: Schmidhuber: &quot;To me it&#39;s indeed weird. Now there are all these letters coming out warning of the dangers of AI. And I think some of the guys who are writing these letters, they are just seeking attention because they know that AI dystopia are attracting more attention than documentaries about the benefits of AI in healthcare.&quot;\n\nSchmidhuber believes we should be more concerned with existing threats like nuclear weapons than speculative risks from advanced AI. He said: &quot;As far as I can judge, all of this cannot be stopped but it can be channeled in a very natural way that is good for humankind...there is a tremendous bias towards good AI, meaning AI that is good for humans...I am much more worried about 60 year old technology that can wipe out civilization within two hours, without any AI.\u201d </p>\n<p>[this is truncated, read show notes]\n</p>\n<p>YT: https://youtu.be/q27XMPm5wg8</p>\n<p>Show notes: https://docs.google.com/document/d/13-vIetOvhceZq5XZnELRbaazpQbxLbf5Yi7M25CixEE/edit?usp=sharing\n\nNote: Interview was recorded 15th June 2023.\nhttps://twitter.com/SchmidhuberAI\n\nPanel: Dr. Tim Scarfe @ecsquendor / Dr. Keith Duggar @DoctorDuggar\n\nPod version: TBA\n\nTOC: \n[00:00:00] Intro / Numerai \n[00:00:51] Show Kick Off \n[00:02:24] Credit Assignment in ML \n[00:12:51] XRisk \n[00:20:45] First Transformer variant of 1991\n[00:47:20] Which Current Approaches are Good \n[00:52:42] Autonomy / Curiosity \n[00:58:42] GANs of 1990\n[01:11:29] OpenAI, Moats, Legislation</p>\n",
    "EnclosureUrl": "https://anchor.fm/s/1e4a0eac/podcast/play/74605343/https%3A%2F%2Fd3ctxlq1ktw2nl.cloudfront.net%2Fstaging%2F2023-7-14%2F31c302ae-c16f-ca62-f807-dac6c80dc9d7.mp3"
}