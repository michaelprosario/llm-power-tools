{
    "Id": "42-56-44-0A-62-AE-EF-E8-A7-E3-47-20-72-F8-42-47-D5-AF-6B-01-18-F7-0B-F1-0E-EF-3E-26-B5-D0-F0-B5",
    "ContentSourceId": "08ddc66c-88c1-4fd9-9d0f-06779ee4a5cb",
    "Title": "Subbarao Kambhampati - Do o1 models search?",
    "SourceUrl": "https://podcasters.spotify.com/pod/show/machinelearningstreettalk/episodes/Subbarao-Kambhampati---Do-o1-models-search-e2ts49m",
    "Description": "<p>Join Prof. Subbarao Kambhampati and host Tim Scarfe for a deep dive into OpenAI&#39;s O1 model and the future of AI reasoning systems. </p>\n<p><br></p>\n<p>* How O1 likely uses reinforcement learning similar to AlphaGo, with hidden reasoning tokens that users pay for but never see</p>\n<p>* The evolution from traditional Large Language Models to more sophisticated reasoning systems</p>\n<p>* The concept of &quot;fractal intelligence&quot; in AI - where models work brilliantly sometimes but fail unpredictably</p>\n<p>* Why O1&#39;s improved performance comes with substantial computational costs</p>\n<p>* The ongoing debate between single-model approaches (OpenAI) vs hybrid systems (Google)</p>\n<p>* The critical distinction between AI as an intelligence amplifier vs autonomous decision-maker</p>\n<p><br></p>\n<p>SPONSOR MESSAGES:</p>\n<p>***</p>\n<p>CentML offers competitive pricing for GenAI model deployment, with flexible options to suit a wide range of models, from small to large-scale deployments. </p>\n<p>https://centml.ai/pricing/</p>\n<p><br></p>\n<p>Tufa AI Labs is a brand new research lab in Zurich started by Benjamin Crouzier focussed on o-series style reasoning and AGI. Are you interested in working on reasoning, or getting involved in their events? </p>\n<p><br></p>\n<p>Goto https://tufalabs.ai/</p>\n<p>***</p>\n<p><br></p>\n<p>TOC:</p>\n<p>1. **O1 Architecture and Reasoning Foundations** </p>\n<p>[00:00:00] 1.1 Fractal Intelligence and Reasoning Model Limitations </p>\n<p>[00:04:28] 1.2 LLM Evolution: From Simple Prompting to Advanced Reasoning  </p>\n<p>[00:14:28] 1.3 O1&#39;s Architecture and AlphaGo-like Reasoning Approach  </p>\n<p>[00:23:18] 1.4 Empirical Evaluation of O1&#39;s Planning Capabilities  </p>\n<p><br></p>\n<p>2. **Monte Carlo Methods and Model Deep-Dive**  </p>\n<p>[00:29:30] 2.1 Monte Carlo Methods and MARCO-O1 Implementation  </p>\n<p>[00:31:30] 2.2 Reasoning vs. Retrieval in LLM Systems  </p>\n<p>[00:40:40] 2.3 Fractal Intelligence Capabilities and Limitations  </p>\n<p>[00:45:59] 2.4 Mechanistic Interpretability of Model Behavior  </p>\n<p>[00:51:41] 2.5 O1 Response Patterns and Performance Analysis  </p>\n<p><br></p>\n<p>3. **System Design and Real-World Applications**  </p>\n<p>[00:59:30] 3.1 Evolution from LLMs to Language Reasoning Models  </p>\n<p>[01:06:48] 3.2 Cost-Efficiency Analysis: LLMs vs O1  </p>\n<p>[01:11:28] 3.3 Autonomous vs Human-in-the-Loop Systems  </p>\n<p>[01:16:01] 3.4 Program Generation and Fine-Tuning Approaches  </p>\n<p>[01:26:08] 3.5 Hybrid Architecture Implementation Strategies  </p>\n<p><br></p>\n<p>Transcript: https://www.dropbox.com/scl/fi/d0ef4ovnfxi0lknirkvft/Subbarao.pdf?rlkey=l3rp29gs4hkut7he8u04mm1df&amp;dl=0</p>\n<p><br></p>\n<p>REFS:</p>\n<p>[00:02:00] Monty Python (1975)</p>\n<p>Witch trial scene: flawed logical reasoning.</p>\n<p>https://www.youtube.com/watch?v=zrzMhU_4m-g</p>\n<p><br></p>\n<p>[00:04:00] Cade Metz (2024)</p>\n<p>Microsoft\u2013OpenAI partnership evolution and control dynamics.</p>\n<p>https://www.nytimes.com/2024/10/17/technology/microsoft-openai-partnership-deal.html</p>\n<p><br></p>\n<p>[00:07:25] Kojima et al. (2022)</p>\n<p>Zero-shot chain-of-thought prompting (&#39;Let&#39;s think step by step&#39;).</p>\n<p>https://arxiv.org/pdf/2205.11916</p>\n<p><br></p>\n<p>[00:12:50] DeepMind Research Team (2023)</p>\n<p>Multi-bot game solving with external and internal planning.</p>\n<p>https://deepmind.google/research/publications/139455/</p>\n<p><br></p>\n<p>[00:15:10] Silver et al. (2016)</p>\n<p>AlphaGo&#39;s Monte Carlo Tree Search and Q-learning.</p>\n<p>https://www.nature.com/articles/nature16961</p>\n<p><br></p>\n<p>[00:16:30] Kambhampati, S. et al. (2023)</p>\n<p>Evaluates O1&#39;s planning in &quot;Strawberry Fields&quot; benchmarks.</p>\n<p>https://arxiv.org/pdf/2410.02162</p>\n<p><br></p>\n<p>[00:29:30] Alibaba AIDC-AI Team (2023)</p>\n<p>MARCO-O1: Chain-of-Thought + MCTS for improved reasoning.</p>\n<p>https://arxiv.org/html/2411.14405</p>\n<p><br></p>\n<p>[00:31:30] Kambhampati, S. (2024)</p>\n<p>Explores LLM &quot;reasoning vs retrieval&quot; debate.</p>\n<p>https://arxiv.org/html/2403.04121v2</p>\n<p><br></p>\n<p>[00:37:35] Wei, J. et al. (2022)</p>\n<p>Chain-of-thought prompting (introduces last-letter concatenation).</p>\n<p>https://arxiv.org/pdf/2201.11903</p>\n<p><br></p>\n<p>[00:42:35] Barbero, F. et al. (2024)</p>\n<p>Transformer attention and &quot;information over-squashing.&quot;</p>\n<p>https://arxiv.org/html/2406.04267v2</p>\n<p><br></p>\n<p>[00:46:05] Ruis, L. et al. (2023)</p>\n<p>Influence functions to understand procedural knowledge in LLMs.</p>\n<p>https://arxiv.org/html/2411.12580v1</p>\n<p><br></p>\n<p>(truncated - continued in shownotes/transcript doc)</p>\n",
    "EnclosureUrl": "https://anchor.fm/s/1e4a0eac/podcast/play/97439478/https%3A%2F%2Fd3ctxlq1ktw2nl.cloudfront.net%2Fstaging%2F2025-0-23%2F9a1ea19a-508f-9cf3-ab02-be2d528461f4.mp3"
}