{
    "Id": "0F-17-C2-C2-03-4B-FB-0D-1B-F1-31-6F-1E-41-5F-F6-48-95-4D-60-C4-FC-42-B6-20-48-80-0D-27-48-B0-22",
    "ContentSourceId": "03e85e81-f3bb-4c2c-944d-b6722870407b",
    "Title": "565: AGI: The Apocalypse Machine",
    "SourceUrl": "https://www.podtrac.com/pts/redirect.mp3/chrt.fm/track/E581B9/arttrk.com/p/VI4CS/pscrb.fm/rss/p/traffic.megaphone.fm/SUPERDATASCIENCEPTYLTD7785383533.mp3?updated=1724658611",
    "Description": "\n        <p>In this episode, Jeremie Harris dives into the stirring topic of AI Safety and the existential risks that Artificial General Intelligence poses to humankind.</p><p><br></p><p>In this episode you will learn:</p><ul>\n<li>Why mentorship is crucial in a data science career development [15:45]</li>\n<li>Canadian vs American start-up ecosystems [24:18]</li>\n<li>What is Artificial General Intelligence (AGI)? [38:50]</li>\n<li>How Artificial Superintelligence could destroy the world [1:04:00]</li>\n<li>How AGI could prove to be a panacea for humankind and life on the planet. [1:27:31]</li>\n<li>How to become an AI safety expert [1:30:07]</li>\n<li>Jeremie's day-to-day work life at Mercurius [1:35:39]</li>\n</ul><p><br></p><p>Additional materials: <a href=\"https://www.superdatascience.com/565\">www.superdatascience.com/565</a></p>\n      ",
    "EnclosureUrl": "https://www.podtrac.com/pts/redirect.mp3/chrt.fm/track/E581B9/arttrk.com/p/VI4CS/pscrb.fm/rss/p/traffic.megaphone.fm/SUPERDATASCIENCEPTYLTD7785383533.mp3?updated=1724658611"
}