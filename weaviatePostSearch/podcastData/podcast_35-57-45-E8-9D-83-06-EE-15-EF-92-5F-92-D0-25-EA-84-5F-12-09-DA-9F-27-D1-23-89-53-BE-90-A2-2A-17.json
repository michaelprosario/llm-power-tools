{
    "Id": "35-57-45-E8-9D-83-06-EE-15-EF-92-5F-92-D0-25-EA-84-5F-12-09-DA-9F-27-D1-23-89-53-BE-90-A2-2A-17",
    "ContentSourceId": "7c098d5f-afc6-488d-b7ac-b49867303173",
    "Title": "ML Can\u00a0Prevent Getting Burned For Kubernetes Provisioning",
    "SourceUrl": "https://thenewstack.simplecast.com/episodes/ml-canprevent-getting-burned-for-kubernetes-provisioning-QJFb_3nu",
    "Description": "<p><span style=\"font-weight: 400;\">In the rush to create, provision and manage Kubernetes, often left out is proper resource provisioning. According to StormForge, a company paying, for example, a million dollars a month on cloud computing resources is likely wasting $6 million a year of resources on the cloud on Kubernetes that are left unused. The reasons for this are manifold and can vary. They include how DevOps teams can tend to estimate too conservatively or aggressively or overspend on resource provisioning. In this podcast with StormForge\u2019s </span><a href=\"https://www.linkedin.com/in/yasminrajabi\"><span style=\"font-weight: 400;\">Yasmin Rajabi,</span></a><span style=\"font-weight: 400;\"> vice president of product management, and </span><a href=\"https://www.linkedin.com/in/bergstrompatrick\"><span style=\"font-weight: 400;\">Patrick Bergstrom</span></a><span style=\"font-weight: 400;\"> CTO, we look at how to properly provision Kubernetes resources and the associated challenges. The podcast was recorded live in Detroit during</span><a href=\"https://events.linuxfoundation.org/kubecon-cloudnativecon-europe/\"><span style=\"font-weight: 400;\"> KubeCon + CloudNativeCon Europe 2022.</span></a></p><p>\u00a0</p><p><p class=\"attribution\"><iframe width=\"100%\" height=\"200px\" frameborder=\"no\" scrolling=\"no\" seamless=\"\" src=\"https://player.simplecast.com/9a45a180-1277-4083-8b55-cafab9a21e18?dark=true\"><span data-mce-type=\"bookmark\" style=\"display: inline-block; width: 0px; overflow: hidden; line-height: 0;\" class=\"mce_SELRES_start\"></span></iframe></p></p><p><span class=\"media-direct-link\"><a href=\"https://thenewstack.simplecast.com/episodes/rethinking-web-application-firewalls\">Rethinking Web Application Firewalls </a></span></p><p>\u00a0</p><p><span style=\"font-weight: 400;\">Almost ironically, the most commonly used Kubernetes resources can even complicate the ability to optimize resources for applications.The processes typically involve Kubernetes resource requests and limits, and predicting how the resources might impact quality of service for pods. Developers deploying an application on Kubernetes often need to set CPU-request, memory-request and other resource limits. \u201cThey are usually like \u2018I don't know \u2014 whatever was there before or whatever the default is,\u2019\u201d Rajabi said. \u201cThey are in the dark.\u201d</span></p><p>\u00a0</p><p><iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/k9cUk8kBXKM\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe></p><p>\u00a0</p><p><span style=\"font-weight: 400;\">Sometimes, developers might use their favorite observability tool and say \u201c\u2018we look where the max is, and then take a guess,\u2019\u201d Rajabi said. \u201cThe challenge is, if you start from there when you start to scale that out \u2014 especially for organizations that are using horizontal scaling with Kubernetes \u2014 is that then you're taking that problem and you're just amplifying it everywhere,\u201d Rajabi said. \u201cAnd so, when you've hit that complexity at scale, taking a second to look back and \u2018say, how do we fix this?\u2019 you don't want to just arbitrarily go reduce resources, because you have to look at the trade off of how that impacts your reliability.\u201d</span></p><p>\u00a0</p><p><span style=\"font-weight: 400;\">The process then becomes very hit or miss. \u201cThat's where it becomes really complex, when there are so many settings across all those environments, all those namespaces,\u201d Rajabi said. \u201cIt's almost a problem that can only be solved by machine learning, which makes it very interesting.\u201d</span></p><p>\u00a0</p><p><span style=\"font-weight: 400;\">But before organizations learn the hard way about not automating optimizing deployments and management of Kubernetes, many resources \u2014 and costs \u2014 are bared to waste. \u201cIt's one of those things that becomes a bigger and bigger challenge, the more you grow as an organization,\u201d Bergstrom said. Many StormForge customers are deploying into thousands of namespaces and thousands of workloads. \u201cYou are suddenly trying to manage each workload individually to make sure it has the resources and the memory that it needs,\u201d Bergstrom said. \u201cIt becomes a bigger and bigger challenge.\u201d</span></p><p>\u00a0</p><p><span style=\"font-weight: 400;\">The process should actually be pain free, when ML is properly implemented. With StormForge\u2019s partnership with </span><a href=\"https://www.datadoghq.com/\"><span style=\"font-weight: 400;\">Datadog</span></a><span style=\"font-weight: 400;\">, it is possible to apply ML to collect historical data, Bergstrom explained. \u201cThen, within just hours of us deploying our algorithm into your environment, we have machine learning that's used two to three weeks worth of data to train that can then automatically set the correct resources for your application. This is \u00a0because we know what the application is actually using,\u201d Bergstrom said. \u201cWe can predict the patterns and we know what it needs in order to be successful.\u201d</span></p>\n",
    "EnclosureUrl": "https://afp-922713-injected.calisto.simplecastaudio.com/5672b58f-7201-4e0e-b0af-da702259d97f/episodes/975973fb-81c3-4aab-acb1-591dfc30e38b/audio/128/default.mp3?aid=rss_feed&awCollectionId=5672b58f-7201-4e0e-b0af-da702259d97f&awEpisodeId=975973fb-81c3-4aab-acb1-591dfc30e38b&feed=IgzWks06"
}