{
    "Id": "31-E2-52-41-AA-97-A6-30-F7-33-93-D3-B3-FD-1D-BB-11-6C-7E-3A-4A-EB-1A-7D-03-E2-71-C1-1D-60-CA-B7",
    "ContentSourceId": "08ddc66c-88c1-4fd9-9d0f-06779ee4a5cb",
    "Title": "Joscha Bach and Connor Leahy on AI risk",
    "SourceUrl": "https://podcasters.spotify.com/pod/show/machinelearningstreettalk/episodes/Joscha-Bach-and-Connor-Leahy-on-AI-risk-e25ukc5",
    "Description": "<p>Support us! https://www.patreon.com/mlst \nMLST Discord: https://discord.gg/aNPkGUQtc5\nTwitter: https://twitter.com/MLStreetTalk\n\nThe first 10 mins of audio from Joscha isn&#39;t great, it improves after.</p>\n<p>\nTranscript and longer summary: https://docs.google.com/document/d/1TUJhlSVbrHf2vWoe6p7xL5tlTK_BGZ140QqqTudF8UI/edit?usp=sharing\n\nDr. Joscha Bach argued that general intelligence emerges from civilization, not individuals. Given our biological constraints, humans cannot achieve a high level of general intelligence on our own. Bach believes AGI may become integrated into all parts of the world, including human minds and bodies. He thinks a future where humans and AGI harmoniously coexist is possible if we develop a shared purpose and incentive to align. However, Bach is uncertain about how AI progress will unfold or which scenarios are most likely.\n\nBach argued that global control and regulation of AI is unrealistic. While regulation may address some concerns, it cannot stop continued progress in AI. He believes individuals determine their own values, so &quot;human values&quot; cannot be formally specified and aligned across humanity. For Bach, the possibility of building beneficial AGI is exciting but much work is still needed to ensure a positive outcome.\n\nConnor Leahy believes we have more control over the future than the default outcome might suggest. With sufficient time and effort, humanity could develop the technology and coordination to build a beneficial AGI. However, the default outcome likely leads to an undesirable scenario if we do not actively work to build a better future. Leahy thinks finding values and priorities most humans endorse could help align AI, even if individuals disagree on some values.\n\nLeahy argued a future where humans and AGI harmoniously coexist is ideal but will require substantial work to achieve. While regulation faces challenges, it remains worth exploring. Leahy believes limits to progress in AI exist but we are unlikely to reach them before humanity is at risk. He worries even modestly superhuman intelligence could disrupt the status quo if misaligned with human values and priorities.\n\nOverall, Bach and Leahy expressed optimism about the possibility of building beneficial AGI but believe we must address risks and challenges proactively. They agreed substantial uncertainty remains around how AI will progress and what scenarios are most plausible. But developing a shared purpose between humans and AI, improving coordination and control, and finding human values to help guide progress could all improve the odds of a beneficial outcome. With openness to new ideas and willingness to consider multiple perspectives, continued discussions like this one could help ensure the future of AI is one that benefits and inspires humanity.\n\nTOC:\n00:00:00 - Introduction and Background\n00:02:54 - Different Perspectives on AGI\n00:13:59 - The Importance of AGI\n00:23:24 - Existential Risks and the Future of Humanity\n00:36:21 - Coherence and Coordination in Society\n00:40:53 - Possibilities and Future of AGI\n00:44:08 - Coherence and alignment\n01:08:32 - The role of values in AI alignment\n01:18:33 - The future of AGI and merging with AI\n01:22:14 - The limits of AI alignment\n01:23:06 - The scalability of intelligence\n01:26:15 - Closing statements and future prospects</p>\n",
    "EnclosureUrl": "https://anchor.fm/s/1e4a0eac/podcast/play/72355653/https%3A%2F%2Fd3ctxlq1ktw2nl.cloudfront.net%2Fstaging%2F2023-5-20%2F81fd6c77-364d-2af5-b47e-98f121101d8a.mp3"
}