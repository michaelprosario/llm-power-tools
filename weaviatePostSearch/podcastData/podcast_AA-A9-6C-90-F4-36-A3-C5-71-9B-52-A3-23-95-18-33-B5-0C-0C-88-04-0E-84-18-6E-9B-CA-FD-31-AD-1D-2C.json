{
    "Id": "AA-A9-6C-90-F4-36-A3-C5-71-9B-52-A3-23-95-18-33-B5-0C-0C-88-04-0E-84-18-6E-9B-CA-FD-31-AD-1D-2C",
    "ContentSourceId": "03e85e81-f3bb-4c2c-944d-b6722870407b",
    "Title": "784: Aligning Large Language Models, with Sinan Ozdemir",
    "SourceUrl": "https://www.podtrac.com/pts/redirect.mp3/chrt.fm/track/E581B9/arttrk.com/p/VI4CS/pscrb.fm/rss/p/traffic.megaphone.fm/SUPERDATASCIENCEPTYLTD3967466186.mp3?updated=1716818936",
    "Description": "\n        <p>Aligning LLMs: How can we teach pre-trained LLMs to hold a conversation and learn new information from each other? This was where Sinan Ozdemir began his investigation into aligning LLMs. In this episode, he talks to Jon Krohn about the limitations of definitions for LLMs, training LLMs, and whether it is possible to train an LLM without alignment.<br><br>Additional materials: <a href=\"https://www.superdatascience.com/784\">www.superdatascience.com/784</a><br><br>Interested in sponsoring a SuperDataScience Podcast episode? Visit <a href=\"https://passionfroot.me/superdatascience\">passionfroot.me/superdatascience</a> for sponsorship information.</p>\n      ",
    "EnclosureUrl": "https://www.podtrac.com/pts/redirect.mp3/chrt.fm/track/E581B9/arttrk.com/p/VI4CS/pscrb.fm/rss/p/traffic.megaphone.fm/SUPERDATASCIENCEPTYLTD3967466186.mp3?updated=1716818936"
}