{
    "Id": "C3-FB-BC-53-46-EA-0D-65-C7-79-04-C0-D7-11-3A-8E-E3-CB-C6-86-59-95-AE-C0-37-EC-7E-21-00-BF-2D-B4",
    "ContentSourceId": "03e85e81-f3bb-4c2c-944d-b6722870407b",
    "Title": "597: A.I. Policy at OpenAI",
    "SourceUrl": "https://www.podtrac.com/pts/redirect.mp3/chrt.fm/track/E581B9/arttrk.com/p/VI4CS/pscrb.fm/rss/p/traffic.megaphone.fm/SUPERDATASCIENCEPTYLTD6491784155.mp3?updated=1720612373",
    "Description": "\n        <p>Dr. Miles Brundage, Head of Policy Research at OpenAI, joins Jon Krohn this week to discuss AI model production, policy, safety, and alignment. Tune in to hear him speak on GPT-3, DALL-E, Codex, and CLIP as well.</p><p><br></p><p>In this episode you will learn:</p><p>\u2022 Miles\u2019 role as Head of Policy Research at OpenAI [4:35]</p><p>\u2022 OpenAI's DALL-E model [7:20]</p><p>\u2022 OpenAI's natural language model GPT-3 [30:43]</p><p>\u2022 OpenAI's automated software-writing model Codex [36:57]</p><p>\u2022 OpenAI\u2019s CLIP model [44:01]</p><p>\u2022 What sets AI policy, AI safety, and AI alignment apart from each other [1:07:03]</p><p>\u2022 How A.I. will likely augment more professions than it displaces them [1:12:06]</p><p><br></p><p>Additional materials: <a href=\"https://www.superdatascience.com/597\">www.superdatascience.com/597</a></p>\n      ",
    "EnclosureUrl": "https://www.podtrac.com/pts/redirect.mp3/chrt.fm/track/E581B9/arttrk.com/p/VI4CS/pscrb.fm/rss/p/traffic.megaphone.fm/SUPERDATASCIENCEPTYLTD6491784155.mp3?updated=1720612373"
}