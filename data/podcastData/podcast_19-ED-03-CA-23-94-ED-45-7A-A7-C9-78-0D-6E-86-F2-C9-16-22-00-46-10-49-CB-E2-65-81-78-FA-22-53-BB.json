{
    "Id": "19-ED-03-CA-23-94-ED-45-7A-A7-C9-78-0D-6E-86-F2-C9-16-22-00-46-10-49-CB-E2-65-81-78-FA-22-53-BB",
    "ContentSourceId": "08ddc66c-88c1-4fd9-9d0f-06779ee4a5cb",
    "Title": "#84 LAURA RUIS - Large language models are not zero-shot communicators [NEURIPS UNPLUGGED]",
    "SourceUrl": "https://podcasters.spotify.com/pod/show/machinelearningstreettalk/episodes/84-LAURA-RUIS---Large-language-models-are-not-zero-shot-communicators-NEURIPS-UNPLUGGED-e1rri6k",
    "Description": "<p>In this NeurIPSs interview, we speak with Laura Ruis about her research on the ability of language models to interpret language in context. She has designed a simple task to evaluate the performance of widely used state-of-the-art language models and has found that they struggle to make pragmatic inferences (implicatures). Tune in to learn more about her findings and what they mean for the future of conversational AI.</p>\n<p><br></p>\n<p>Laura Ruis</p>\n<p>https://www.lauraruis.com/</p>\n<p>https://twitter.com/LauraRuis</p>\n<p><br></p>\n<p>BLOOM</p>\n<p>https://bigscience.huggingface.co/blog/bloom</p>\n<p><br></p>\n<p>Large language models are not zero-shot communicators [Laura Ruis, Akbir Khan, Stella Biderman, Sara Hooker, Tim Rockt\u00e4schel, Edward Grefenstette]</p>\n<p>https://arxiv.org/abs/2210.14986</p>\n<p><br></p>\n<p>[Zhang et al] OPT: Open Pre-trained Transformer Language Models</p>\n<p>https://arxiv.org/pdf/2205.01068.pdf</p>\n<p><br></p>\n<p>[Lampinen] Can language models handle recursively nested grammatical structures? A case study on comparing models and humans</p>\n<p>https://arxiv.org/pdf/2210.15303.pdf</p>\n<p><br></p>\n<p>[Gary Marcus] Horse rides astronaut</p>\n<p>https://garymarcus.substack.com/p/horse-rides-astronaut</p>\n<p><br></p>\n<p>[Gary Marcus] GPT-3, Bloviator: OpenAI\u2019s language generator has no idea what it\u2019s talking about</p>\n<p>https://www.technologyreview.com/2020/08/22/1007539/gpt3-openai-language-generator-artificial-intelligence-ai-opinion/</p>\n<p><br></p>\n<p>[Bender et al] On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?</p>\n<p>https://dl.acm.org/doi/10.1145/3442188.3445922&nbsp;</p>\n<p><br></p>\n<p>[janus] Simulators (Less Wrong)</p>\n<p>https://www.lesswrong.com/posts/vJFdjigzmcXMhNTsx/simulators</p>\n",
    "EnclosureUrl": "https://anchor.fm/s/1e4a0eac/podcast/play/61769364/https%3A%2F%2Fd3ctxlq1ktw2nl.cloudfront.net%2Fstaging%2F2022-11-6%2F0b5fdbf7-c39d-a59e-34ae-68a8b363175a.mp3"
}