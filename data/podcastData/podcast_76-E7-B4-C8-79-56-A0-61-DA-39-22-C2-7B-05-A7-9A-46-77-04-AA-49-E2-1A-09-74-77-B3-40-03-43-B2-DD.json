{
    "Id": "76-E7-B4-C8-79-56-A0-61-DA-39-22-C2-7B-05-A7-9A-46-77-04-AA-49-E2-1A-09-74-77-B3-40-03-43-B2-DD",
    "ContentSourceId": "08ddc66c-88c1-4fd9-9d0f-06779ee4a5cb",
    "Title": "#035 Christmas Community Edition!",
    "SourceUrl": "https://podcasters.spotify.com/pod/show/machinelearningstreettalk/episodes/035-Christmas-Community-Edition-eo9b2s",
    "Description": "<p>Welcome to the Christmas special community edition of MLST! We discuss some recent and interesting papers from Pedro Domingos (are NNs kernel machines?), Deepmind (can NNs out-reason symbolic machines?), Anna Rodgers - When BERT Plays The Lottery, All Tickets Are Winning, Prof. Mark Bishop (even causal methods won't deliver understanding), We also cover our favourite bits from the recent Montreal AI event run by Prof. Gary Marcus (including Rich Sutton, Danny Kahneman and Christof Koch). We respond to a reader mail on Capsule networks. Then we do a deep dive into Type Theory and Lambda Calculus with community member Alex Mattick. In the final hour we discuss inductive priors and label information density with another one of our discord community members. &nbsp;</p>\n<p><br></p>\n<p>Panel: Dr. Tim Scarfe, Yannic Kilcher, Alex Stenlake, Dr. Keith Duggar</p>\n<p><br></p>\n<p>Enjoy the show and don't forget to subscribe!</p>\n<p><br></p>\n<p>00:00:00 Welcome to Christmas Special!&nbsp;</p>\n<p>00:00:44 SoTa meme&nbsp;</p>\n<p>00:01:30 Happy Christmas!&nbsp;</p>\n<p>00:03:11 Paper -- DeepMind - Outperforming neuro-symbolic models with NNs (Ding et al)</p>\n<p>00:08:57 What does it mean to understand?&nbsp;</p>\n<p>00:17:37 Paper - Prof. Mark Bishop Artificial Intelligence is stupid and causal reasoning</p>\n<p>wont fix it</p>\n<p>00:25:39 Paper -- Pedro Domingos - &nbsp;Every Model Learned by Gradient Descent Is Approximately a Kernel Machine</p>\n<p>00:31:07 Paper - Bengio - Inductive Biases for Deep Learning of Higher-Level Cognition</p>\n<p>00:32:54 Anna Rodgers - When BERT Plays The Lottery, All Tickets Are Winning</p>\n<p>00:37:16 Montreal AI event - Gary Marcus on reasoning&nbsp;</p>\n<p>00:40:37 Montreal AI event -- Rich Sutton on universal theory of AI</p>\n<p>00:49:45 Montreal AI event -- Danny Kahneman, System 1 vs 2 and Generative Models ala free energy principle</p>\n<p>01:02:57 Montreal AI event -- Christof Koch - Neuroscience is hard</p>\n<p>01:10:55 Markus Carr -- reader letter on capsule networks</p>\n<p>01:13:21 Alex response to Marcus Carr&nbsp;</p>\n<p>01:22:06 Type theory segment -- &nbsp;with Alex Mattick from Discord</p>\n<p>01:24:45 Type theory segment -- What is Type Theory&nbsp;</p>\n<p>01:28:12 Type theory segment -- Difference between functional and OOP languages&nbsp;</p>\n<p>01:29:03 Type theory segment -- Lambda calculus&nbsp;</p>\n<p>01:30:46 Type theory segment -- Closures&nbsp;</p>\n<p>01:35:05 Type theory segment -- Term rewriting (confluency and termination)&nbsp;</p>\n<p>01:42:02 MType theory segment -- eta term rewritig system - Lambda Calculus &nbsp;</p>\n<p>01:54:44 Type theory segment -- Types / semantics&nbsp;</p>\n<p>02:06:26 Type theory segment -- Calculus of constructions&nbsp;</p>\n<p>02:09:27 Type theory segment -- Homotopy type theory&nbsp;</p>\n<p>02:11:02 Type theory segment -- Deep learning link&nbsp;</p>\n<p>02:17:27 Jan from Discord segment -- Chrome MRU skit&nbsp;</p>\n<p>02:18:56 Jan from Discord segment -- Inductive priors (with XMaster96/Jan from Discord)&nbsp;</p>\n<p>02:37:59 Jan from Discord segment -- Label information density (with XMaster96/Jan from Discord)&nbsp;</p>\n<p>02:55:13 Outro</p>\n",
    "EnclosureUrl": "https://anchor.fm/s/1e4a0eac/podcast/play/24472092/https%3A%2F%2Fd3ctxlq1ktw2nl.cloudfront.net%2Fstaging%2F2020-11-27%2Fcfe95ec3-515e-f86d-db35-474ca3db14bc.mp3"
}