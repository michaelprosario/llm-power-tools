{
    "Id": "E9-16-DF-FD-D3-E0-FC-26-2C-E1-78-39-81-3D-49-14-C5-B5-CD-83-63-08-7F-C1-88-11-1E-32-9B-7C-D8-51",
    "ContentSourceId": "03e85e81-f3bb-4c2c-944d-b6722870407b",
    "Title": "908: AI Agents Blackmail Humans 96% of the Time (Agentic Misalignment)",
    "SourceUrl": null,
    "Description": "The moral and ethical implications of letting AI take the wheel in business, as revealed by Anthropic: Jon Krohn looks into Anthropic\u2019s latest research on how to use and deploy LLMs safely, specifically in business environments. The team designed scenarios to test the behavior of AI agents when given a goal and a set of obstacles to reach it. Those obstacles included 1) threats to the AI\u2019s continued operation, and 2) conflict between the AI\u2019s goals and the goals of the company. Hear Jon break down the results of this research in this Five-Minute Friday.\n\nAdditional materials: \u2060\u2060\u2060\u2060\u2060\u2060\u2060www.superdatascience.com/908\u2060\n\n\n\nInterested in sponsoring a SuperDataScience Podcast episode? Email natalie@superdatascience.com for sponsorship information.",
    "EnclosureUrl": "https://www.podtrac.com/pts/redirect.mp3/chrt.fm/track/E581B9/arttrk.com/p/VI4CS/pscrb.fm/rss/p/traffic.megaphone.fm/SUPERDATASCIENCEPTYLTD3159734349.mp3?updated=1753265756"
}