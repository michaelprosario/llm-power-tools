{
    "Id": "AE-53-10-A9-BE-2C-8C-64-C6-23-A4-01-DB-15-27-11-A6-E7-53-53-F2-BB-59-23-4A-08-32-58-09-E8-9D-8A",
    "ContentSourceId": "08ddc66c-88c1-4fd9-9d0f-06779ee4a5cb",
    "Title": "#063 - Prof. YOSHUA BENGIO - GFlowNets, Consciousness & Causality",
    "SourceUrl": "https://podcasters.spotify.com/pod/show/machinelearningstreettalk/episodes/063---Prof--YOSHUA-BENGIO---GFlowNets--Consciousness--Causality-e1enlor",
    "Description": "<p>We are now sponsored by Weights and Biases! Please visit our sponsor link: http://wandb.me/MLST</p>\n<p>Patreon: https://www.patreon.com/mlst</p>\n<p>For Yoshua Bengio, GFlowNets are the most exciting thing on the horizon of Machine Learning today. He believes they can solve previously intractable problems and hold the key to unlocking machine abstract reasoning itself. This discussion explores the promise of GFlowNets and the personal journey Prof. Bengio traveled to reach them.</p>\n<p>Panel:</p>\n<p>Dr. Tim Scarfe</p>\n<p>Dr. Keith Duggar</p>\n<p>Dr. Yannic Kilcher</p>\n<p><br></p>\n<p>Our special thanks to:&nbsp;</p>\n<p>- Alexander Mattick (Zickzack)</p>\n<p>References:</p>\n<p>Yoshua Bengio @ MILA (https://mila.quebec/en/person/bengio-yoshua/)</p>\n<p>GFlowNet Foundations (https://arxiv.org/pdf/2111.09266.pdf)</p>\n<p>Flow Network based Generative Models for Non-Iterative Diverse Candidate Generation (https://arxiv.org/pdf/2106.04399.pdf)</p>\n<p>Interpolation Consistency Training for Semi-Supervised Learning (https://arxiv.org/pdf/1903.03825.pdf)</p>\n<p>Towards Causal Representation Learning (https://arxiv.org/pdf/2102.11107.pdf)</p>\n<p>Causal inference using invariant prediction: identification and confidence intervals (https://arxiv.org/pdf/1501.01332.pdf)</p>\n",
    "EnclosureUrl": "https://anchor.fm/s/1e4a0eac/podcast/play/48010459/https%3A%2F%2Fd3ctxlq1ktw2nl.cloudfront.net%2Fstaging%2F2022-1-21%2F8ff3e9bb-1aff-6fef-2c2e-140852498452.mp3"
}