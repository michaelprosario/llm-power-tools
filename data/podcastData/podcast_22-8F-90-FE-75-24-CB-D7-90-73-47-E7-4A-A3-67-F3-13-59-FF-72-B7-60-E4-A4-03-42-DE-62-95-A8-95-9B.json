{
    "Id": "22-8F-90-FE-75-24-CB-D7-90-73-47-E7-4A-A3-67-F3-13-59-FF-72-B7-60-E4-A4-03-42-DE-62-95-A8-95-9B",
    "ContentSourceId": "08ddc66c-88c1-4fd9-9d0f-06779ee4a5cb",
    "Title": "One Shot and Metric Learning - Quadruplet Loss (Machine Learning Dojo)",
    "SourceUrl": "https://podcasters.spotify.com/pod/show/machinelearningstreettalk/episodes/One-Shot-and-Metric-Learning---Quadruplet-Loss-Machine-Learning-Dojo-eet4kb",
    "Description": "<p>*Note this is an episode from Tim's Machine Learning Dojo YouTube channel.&nbsp;</p>\n<p>Join Eric Craeymeersch on a wonderful discussion all about ML engineering, computer vision, siamese networks, contrastive loss, one shot learning and metric learning.&nbsp;</p>\n<p>00:00:00 Introduction&nbsp;</p>\n<p>00:11:47 ML Engineering Discussion</p>\n<p>00:35:59 Intro to the main topic</p>\n<p>00:42:13 Siamese Networks</p>\n<p>00:48:36 Mining strategies</p>\n<p>00:51:15 Contrastive Loss</p>\n<p>00:57:44 Trip loss paper</p>\n<p>01:09:35 Quad loss paper</p>\n<p>01:25:49 Eric's Quadloss Medium Article&nbsp;</p>\n<p>02:17:32 Metric learning reality check</p>\n<p>02:21:06 Engineering discussion II</p>\n<p>02:26:22 Outro</p>\n<p>In our second paper review call, Tess Ferrandez covered off the FaceNet paper from Google which was a one-shot siamese network with the so called triplet loss. It was an interesting change of direction for NN architecture i.e. using a contrastive loss instead of having a fixed number of output classes. Contrastive architectures have been taking over the ML landscape recently i.e. SimCLR, MOCO, BERT.&nbsp;</p>\n<p>Eric wrote an article about this at the time: https://medium.com/@crimy/one-shot-learning-siamese-networks-and-triplet-loss-with-keras-2885ed022352&nbsp;</p>\n<p>He then discovered there was a new approach to one shot learning in vision using a quadruplet loss and metric learning. Eric wrote a new article and several experiments on this @ https://medium.com/@crimy/beyond-triplet-loss-one-shot-learning-experiments-with-quadruplet-loss-16671ed51290?source=friends_link&amp;sk=bf41673664ad8a52e322380f2a456e8b</p>\n<p>Paper details:&nbsp;</p>\n<p>Beyond triplet loss: a deep quadruplet network for person re-identification</p>\n<p>https://arxiv.org/abs/1704.01719 (Chen at al '17)</p>\n<p>\"Person re-identification (ReID) is an important task in wide area video surveillance which focuses on identifying people across different cameras. Recently, deep learning networks with a triplet loss become a common framework for person ReID. However, the triplet loss pays main attentions on obtaining correct orders on the training set. It still suffers from a weaker generalization capability from the training set to the testing set, thus resulting in inferior performance. In this paper, we design a quadruplet loss, which can lead to the model output with a larger inter-class variation and a smaller intra-class variation compared to the triplet loss. As a result, our model has a better generalization ability and can achieve a higher performance on the testing set. In particular, a quadruplet deep network using a margin-based online hard negative mining is proposed based on the quadruplet loss for the person ReID. In extensive experiments, the proposed network outperforms most of the state-of-the-art algorithms on representative datasets which clearly demonstrates the effectiveness of our proposed method.\"</p>\n<p>Original facenet paper;&nbsp;</p>\n<p>https://arxiv.org/abs/1503.03832</p>\n<p>#deeplearning #machinelearning</p>\n",
    "EnclosureUrl": "https://anchor.fm/s/1e4a0eac/podcast/play/14635083/https%3A%2F%2Fd3ctxlq1ktw2nl.cloudfront.net%2Fproduction%2F2020-5-2%2F78855008-44100-2-15cfdc796862e.mp3"
}