{
    "Id": "CF-B9-17-8C-CE-1A-C3-8C-A2-72-CF-E4-47-4C-C5-8E-3D-1E-68-EB-CC-A4-82-E9-CB-77-01-50-A8-F9-AF-E6",
    "ContentSourceId": "08ddc66c-88c1-4fd9-9d0f-06779ee4a5cb",
    "Title": "How Machines Learn to Ignore the Noise (Kevin Ellis + Zenna Tavares)",
    "SourceUrl": "https://podcasters.spotify.com/pod/show/machinelearningstreettalk/episodes/How-Machines-Learn-to-Ignore-the-Noise-Kevin-Ellis--Zenna-Tavares-e319n04",
    "Description": "<p>Prof. Kevin Ellis and Dr. Zenna Tavares talk about making AI smarter, like humans. They want AI to learn from just a little bit of information by actively trying things out, not just by looking at tons of data.</p><p><br></p><p>They discuss two main ways AI can &quot;think&quot;: one way is like following specific rules or steps (like a computer program), and the other is more intuitive, like guessing based on patterns (like modern AI often does). They found combining both methods works well for solving complex puzzles like ARC.</p><p><br></p><p>A key idea is &quot;compositionality&quot; - building big ideas from small ones, like LEGOs. This is powerful but can also be overwhelming. Another important idea is &quot;abstraction&quot; - understanding things simply, without getting lost in details, and knowing there are different levels of understanding.</p><p><br></p><p>Ultimately, they believe the best AI will need to explore, experiment, and build models of the world, much like humans do when learning something new.</p><p><br></p><p>SPONSOR MESSAGES:</p><p>***</p><p>Tufa AI Labs is a brand new research lab in Zurich started by Benjamin Crouzier focussed on o-series style reasoning and AGI. They are hiring a Chief Engineer and ML engineers. Events in Zurich. </p><p><br></p><p>Goto https://tufalabs.ai/</p><p>***</p><p><br></p><p>TRANSCRIPT:</p><p>https://www.dropbox.com/scl/fi/3ngggvhb3tnemw879er5y/BASIS.pdf?rlkey=lr2zbj3317mex1q5l0c2rsk0h&amp;dl=0</p><p> </p><p>Zenna Tavares:</p><p>http://www.zenna.org/</p><p>Kevin Ellis:</p><p>https://www.cs.cornell.edu/~ellisk/</p><p><br></p><p>TOC:</p><p>1. Compositionality and Learning Foundations</p><p> [00:00:00] 1.1 Compositional Search and Learning Challenges</p><p> [00:03:55] 1.2 Bayesian Learning and World Models</p><p>   [00:12:05] 1.3 Programming Languages and Compositionality Trade-offs</p><p>   [00:15:35] 1.4 Inductive vs Transductive Approaches in AI Systems</p><p><br></p><p>2. Neural-Symbolic Program Synthesis</p><p>   [00:27:20] 2.1 Integration of LLMs with Traditional Programming and Meta-Programming</p><p>   [00:30:43] 2.2 Wake-Sleep Learning and DreamCoder Architecture</p><p>   [00:38:26] 2.3 Program Synthesis from Interactions and Hidden State Inference</p><p>   [00:41:36] 2.4 Abstraction Mechanisms and Resource Rationality</p><p>   [00:48:38] 2.5 Inductive Biases and Causal Abstraction in AI Systems</p><p><br></p><p>3. Abstract Reasoning Systems</p><p>   [00:52:10] 3.1 Abstract Concepts and Grid-Based Transformations in ARC</p><p>   [00:56:08] 3.2 Induction vs Transduction Approaches in Abstract Reasoning</p><p>   [00:59:12] 3.3 ARC Limitations and Interactive Learning Extensions</p><p>   [01:06:30] 3.4 Wake-Sleep Program Learning and Hybrid Approaches</p><p>   [01:11:37] 3.5 Project MARA and Future Research Directions</p><p><br></p><p>REFS:</p><p>[00:00:25] DreamCoder, Kevin Ellis et al.</p><p>https://arxiv.org/abs/2006.08381</p><p><br></p><p>[00:01:10] Mind Your Step, Ryan Liu et al.</p><p>https://arxiv.org/abs/2410.21333</p><p><br></p><p>[00:06:05] Bayesian inference, Griffiths, T. L., Kemp, C., &amp; Tenenbaum, J. B.</p><p>https://psycnet.apa.org/record/2008-06911-003</p><p><br></p><p>[00:13:00] Induction and Transduction, Wen-Ding Li, Zenna Tavares, Yewen Pu, Kevin Ellis</p><p>https://arxiv.org/abs/2411.02272</p><p><br></p><p>[00:23:15] Neurosymbolic AI, Garcez, Artur d&#39;Avila et al.</p><p>https://arxiv.org/abs/2012.05876</p><p><br></p><p>[00:33:50] Induction and Transduction (II), Wen-Ding Li, Kevin Ellis et al.</p><p>https://arxiv.org/abs/2411.02272</p><p><br></p><p>[00:38:35] ARC, Fran\u00e7ois Chollet</p><p>https://arxiv.org/abs/1911.01547</p><p><br></p><p>[00:39:20] Causal Reactive Programs, Ria Das, Joshua B. Tenenbaum, Armando Solar-Lezama, Zenna Tavares</p><p>http://www.zenna.org/publications/autumn2022.pdf</p><p><br></p><p>[00:42:50] MuZero, Julian Schrittwieser et al.</p><p>http://arxiv.org/pdf/1911.08265</p><p><br></p><p>[00:43:20] VisualPredicator, Yichao Liang</p><p>https://arxiv.org/abs/2410.23156</p><p><br></p><p>[00:48:55] Bayesian models of cognition, Joshua B. Tenenbaum</p><p>https://mitpress.mit.edu/9780262049412/bayesian-models-of-cognition/</p><p><br></p><p>[00:49:30] The Bitter Lesson, Rich Sutton</p><p>http://www.incompleteideas.net/IncIdeas/BitterLesson.html</p><p><br></p><p>[01:06:35] Program induction, Kevin Ellis, Wen-Ding Li</p><p>https://arxiv.org/pdf/2411.02272</p><p><br></p><p>[01:06:50] DreamCoder (II), Kevin Ellis et al.</p><p>https://arxiv.org/abs/2006.08381</p><p><br></p><p>[01:11:55] Project MARA, Zenna Tavares, Kevin Ellis</p><p>https://www.basis.ai/blog/mara/</p>\n",
    "EnclosureUrl": "https://anchor.fm/s/1e4a0eac/podcast/play/101030340/https%3A%2F%2Fd3ctxlq1ktw2nl.cloudfront.net%2Fstaging%2F2025-3-8%2Feca73139-5076-05da-1c71-0c4421ae52e9.mp3"
}