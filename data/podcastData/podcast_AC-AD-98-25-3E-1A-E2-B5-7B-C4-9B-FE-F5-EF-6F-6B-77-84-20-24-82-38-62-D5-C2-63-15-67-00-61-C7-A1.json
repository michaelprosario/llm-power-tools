{
    "Id": "AC-AD-98-25-3E-1A-E2-B5-7B-C4-9B-FE-F5-EF-6F-6B-77-84-20-24-82-38-62-D5-C2-63-15-67-00-61-C7-A1",
    "ContentSourceId": "08ddc66c-88c1-4fd9-9d0f-06779ee4a5cb",
    "Title": "Want to Understand Neural Networks? Think Elastic Origami! - Prof. Randall Balestriero",
    "SourceUrl": "https://podcasters.spotify.com/pod/show/machinelearningstreettalk/episodes/Want-to-Understand-Neural-Networks--Think-Elastic-Origami----Prof--Randall-Balestriero-e2ujg9u",
    "Description": "<p>Professor Randall Balestriero joins us to discuss neural network geometry, spline theory, and emerging phenomena in deep learning, based on research presented at ICML. Topics include the delayed emergence of adversarial robustness in neural networks (&quot;grokking&quot;), geometric interpretations of neural networks via spline theory, and challenges in reconstruction learning. We also cover geometric analysis of Large Language Models (LLMs) for toxicity detection and the relationship between intrinsic dimensionality and model control in RLHF.</p><p><br></p><p>SPONSOR MESSAGES:</p><p>***</p><p>CentML offers competitive pricing for GenAI model deployment, with flexible options to suit a wide range of models, from small to large-scale deployments.</p><p>https://centml.ai/pricing/</p><p><br></p><p>Tufa AI Labs is a brand new research lab in Zurich started by Benjamin Crouzier focussed on o-series style reasoning and AGI. Are you interested in working on reasoning, or getting involved in their events?</p><p><br></p><p>Goto https://tufalabs.ai/</p><p>***</p><p><br></p><p>Randall Balestriero</p><p>https://x.com/randall_balestr</p><p>https://randallbalestriero.github.io/</p><p><br></p><p>Show notes and transcript: https://www.dropbox.com/scl/fi/3lufge4upq5gy0ug75j4a/RANDALLSHOW.pdf?rlkey=nbemgpa0jhawt1e86rx7372e4&amp;dl=0</p><p><br></p><p><br></p><p>TOC:</p><p>- Introduction</p><p>    - 00:00:00: Introduction</p><p>- Neural Network Geometry and Spline Theory</p><p>    - 00:01:41: Neural Network Geometry and Spline Theory</p><p>    - 00:07:41: Deep Networks Always Grok</p><p>    - 00:11:39: Grokking and Adversarial Robustness</p><p>    - 00:16:09: Double Descent and Catastrophic Forgetting</p><p>- Reconstruction Learning</p><p>    - 00:18:49: Reconstruction Learning</p><p>    - 00:24:15: Frequency Bias in Neural Networks</p><p>- Geometric Analysis of Neural Networks</p><p>    - 00:29:02: Geometric Analysis of Neural Networks</p><p>    - 00:34:41: Adversarial Examples and Region Concentration</p><p>- LLM Safety and Geometric Analysis</p><p>    - 00:40:05: LLM Safety and Geometric Analysis</p><p>    - 00:46:11: Toxicity Detection in LLMs</p><p>    - 00:52:24: Intrinsic Dimensionality and Model Control</p><p>    - 00:58:07: RLHF and High-Dimensional Spaces</p><p>- Conclusion</p><p>    - 01:02:13: Neural Tangent Kernel</p><p>    - 01:08:07: Conclusion</p><p><br></p><p><br></p><p>REFS:</p><p>[00:01:35] Humayun \u2013 Deep network geometry &amp; input space partitioning</p><p>https://arxiv.org/html/2408.04809v1</p><p><br></p><p>[00:03:55] Balestriero &amp; Paris \u2013 Linking deep networks to adaptive spline operators</p><p>https://proceedings.mlr.press/v80/balestriero18b/balestriero18b.pdf</p><p><br></p><p>[00:13:55] Song et al. \u2013 Gradient-based white-box adversarial attacks</p><p>https://arxiv.org/abs/2012.14965</p><p><br></p><p>[00:16:05] Humayun, Balestriero &amp; Baraniuk \u2013 Grokking phenomenon &amp; emergent robustness</p><p>https://arxiv.org/abs/2402.15555</p><p><br></p><p>[00:18:25] Humayun \u2013 Training dynamics &amp; double descent via linear region evolution</p><p>https://arxiv.org/abs/2310.12977</p><p><br></p><p>[00:20:15] Balestriero \u2013 Power diagram partitions in DNN decision boundaries</p><p>https://arxiv.org/abs/1905.08443</p><p><br></p><p>[00:23:00] Frankle &amp; Carbin \u2013 Lottery Ticket Hypothesis for network pruning</p><p>https://arxiv.org/abs/1803.03635</p><p><br></p><p>[00:24:00] Belkin et al. \u2013 Double descent phenomenon in modern ML</p><p>https://arxiv.org/abs/1812.11118</p><p><br></p><p>[00:25:55] Balestriero et al. \u2013 Batch normalization\u2019s regularization effects</p><p>https://arxiv.org/pdf/2209.14778</p><p><br></p><p>[00:29:35] EU \u2013 EU AI Act 2024 with compute restrictions</p><p>https://www.lw.com/admin/upload/SiteAttachments/EU-AI-Act-Navigating-a-Brave-New-World.pdf</p><p><br></p><p>[00:39:30] Humayun, Balestriero &amp; Baraniuk \u2013 SplineCam: Visualizing deep network geometry</p><p>https://openaccess.thecvf.com/content/CVPR2023/papers/Humayun_SplineCam_Exact_Visualization_and_Characterization_of_Deep_Network_Geometry_and_CVPR_2023_paper.pdf</p><p><br></p><p>[00:40:40] Carlini \u2013 Trade-offs between adversarial robustness and accuracy</p><p>https://arxiv.org/pdf/2407.20099</p><p><br></p><p>[00:44:55] Balestriero &amp; LeCun \u2013 Limitations of reconstruction-based learning methods</p><p>https://openreview.net/forum?id=ez7w0Ss4g9</p><p>(truncated, see shownotes PDF)</p><p><br></p>\n",
    "EnclosureUrl": "https://anchor.fm/s/1e4a0eac/podcast/play/98205438/https%3A%2F%2Fd3ctxlq1ktw2nl.cloudfront.net%2Fstaging%2F2025-1-8%2F0d2541ce-6d8a-f729-83eb-feb798bbbd9b.mp3"
}