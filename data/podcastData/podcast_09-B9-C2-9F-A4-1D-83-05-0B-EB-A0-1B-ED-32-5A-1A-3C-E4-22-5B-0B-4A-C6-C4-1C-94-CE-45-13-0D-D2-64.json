{
    "Id": "09-B9-C2-9F-A4-1D-83-05-0B-EB-A0-1B-ED-32-5A-1A-3C-E4-22-5B-0B-4A-C6-C4-1C-94-CE-45-13-0D-D2-64",
    "ContentSourceId": "08ddc66c-88c1-4fd9-9d0f-06779ee4a5cb",
    "Title": "Jay Alammar on LLMs, RAG, and AI Engineering",
    "SourceUrl": "https://podcasters.spotify.com/pod/show/machinelearningstreettalk/episodes/Jay-Alammar-on-LLMs--RAG--and-AI-Engineering-e2n2koj",
    "Description": "<p>Jay Alammar, renowned AI educator and researcher at Cohere, discusses the latest developments in large language models (LLMs) and their applications in industry. Jay shares his expertise on retrieval augmented generation (RAG), semantic search, and the future of AI architectures.</p>\n<p><br></p>\n<p>MLST is sponsored by Brave:</p>\n<p>The Brave Search API covers over 20 billion webpages, built from scratch without Big Tech biases or the recent extortionate price hikes on search API access. Perfect for AI model training and retrieval augmentated generation. Try it now - get 2,000 free queries monthly at http://brave.com/api. </p>\n<p><br></p>\n<p>Cohere Command R model series: https://cohere.com/command</p>\n<p><br></p>\n<p>Jay Alamaar:</p>\n<p>https://x.com/jayalammar</p>\n<p><br></p>\n<p>Buy Jay&#39;s new book here!</p>\n<p>Hands-On Large Language Models: Language Understanding and Generation</p>\n<p>https://amzn.to/4fzOUgh</p>\n<p><br></p>\n<p>TOC:</p>\n<p>00:00:00 Introduction to Jay Alammar and AI Education</p>\n<p>00:01:47 Cohere&#39;s Approach to RAG and AI Re-ranking</p>\n<p>00:07:15 Implementing AI in Enterprise: Challenges and Solutions</p>\n<p>00:09:26 Jay&#39;s Role at Cohere and the Importance of Learning in Public</p>\n<p>00:15:16 The Evolution of AI in Industry: From Deep Learning to LLMs</p>\n<p>00:26:12 Expert Advice for Newcomers in Machine Learning</p>\n<p>00:32:39 The Power of Semantic Search and Embeddings in AI Systems</p>\n<p>00:37:59 Jay Alammar&#39;s Journey as an AI Educator and Visualizer</p>\n<p>00:43:36 Visual Learning in AI: Making Complex Concepts Accessible</p>\n<p>00:47:38 Strategies for Keeping Up with Rapid AI Advancements</p>\n<p>00:49:12 The Future of Transformer Models and AI Architectures</p>\n<p>00:51:40 Evolution of the Transformer: From 2017 to Present</p>\n<p>00:54:19 Preview of Jay&#39;s Upcoming Book on Large Language Models</p>\n<p><br></p>\n<p>Disclaimer: This is the fourth video from our Cohere partnership. We were not told what to say in the interview, and didn&#39;t edit anything out from the interview. Note also that this combines several previously unpublished interviews from Jay into one, the earlier one at Tim&#39;s house was shot in Aug 2023, and the more recent one in Toronto in May 2024. </p>\n<p><br></p>\n<p>Refs:</p>\n<p>The Illustrated Transformer</p>\n<p>https://jalammar.github.io/illustrated-transformer/</p>\n<p><br></p>\n<p>Attention Is All You Need</p>\n<p>https://arxiv.org/abs/1706.03762</p>\n<p><br></p>\n<p>The Unreasonable Effectiveness of Recurrent Neural Networks</p>\n<p>http://karpathy.github.io/2015/05/21/rnn-effectiveness/</p>\n<p><br></p>\n<p>Neural Networks in 11 Lines of Code</p>\n<p>https://iamtrask.github.io/2015/07/12/basic-python-network/</p>\n<p><br></p>\n<p>Understanding LSTM Networks (Chris Olah&#39;s blog post)</p>\n<p>http://colah.github.io/posts/2015-08-Understanding-LSTMs/</p>\n<p><br></p>\n<p>Luis Serrano&#39;s YouTube Channel</p>\n<p>https://www.youtube.com/channel/UCgBncpylJ1kiVaPyP-PZauQ</p>\n<p><br></p>\n<p>Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks</p>\n<p>https://arxiv.org/abs/1908.10084</p>\n<p><br></p>\n<p>GPT (Generative Pre-trained Transformer) models</p>\n<p>https://jalammar.github.io/illustrated-gpt2/</p>\n<p>https://openai.com/research/gpt-4</p>\n<p><br></p>\n<p>BERT (Bidirectional Encoder Representations from Transformers)</p>\n<p>https://jalammar.github.io/illustrated-bert/</p>\n<p>https://arxiv.org/abs/1810.04805</p>\n<p><br></p>\n<p>RoPE (Rotary Positional Encoding)</p>\n<p>https://arxiv.org/abs/2104.09864 (Linked paper discussing rotary embeddings)</p>\n<p><br></p>\n<p>Grouped Query Attention</p>\n<p>https://arxiv.org/pdf/2305.13245</p>\n<p><br></p>\n<p>RLHF (Reinforcement Learning from Human Feedback)</p>\n<p>https://openai.com/research/learning-from-human-preferences</p>\n<p>https://arxiv.org/abs/1706.03741</p>\n<p><br></p>\n<p>DPO (Direct Preference Optimization)</p>\n<p>https://arxiv.org/abs/2305.18290</p>\n",
    "EnclosureUrl": "https://anchor.fm/s/1e4a0eac/podcast/play/90312915/https%3A%2F%2Fd3ctxlq1ktw2nl.cloudfront.net%2Fstaging%2F2024-7-11%2F9be9c216-1f7a-6045-b79c-2dfedc30d327.mp3"
}