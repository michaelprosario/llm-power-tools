{
    "Id": "48-80-37-73-5E-7D-0A-3A-BB-10-B9-0D-46-E5-B6-F7-28-36-F3-AC-F2-31-0E-83-01-D7-07-D0-8A-A0-2B-81",
    "ContentSourceId": "08ddc66c-88c1-4fd9-9d0f-06779ee4a5cb",
    "Title": "#041 - Biologically Plausible Neural Networks - Dr. Simon Stringer",
    "SourceUrl": "https://podcasters.spotify.com/pod/show/machinelearningstreettalk/episodes/041---Biologically-Plausible-Neural-Networks---Dr--Simon-Stringer-ept4db",
    "Description": "<p>Dr. Simon Stringer. Obtained his Ph.D in mathematical state space control theory and has been a Senior Research Fellow at Oxford University for over 27 years. Simon is the director of the the Oxford Centre for Theoretical Neuroscience and Artificial Intelligence, which is based within the Oxford University Department of Experimental Psychology. His department covers vision, spatial processing, motor function, language and consciousness -- in particular -- how the primate visual system learns to make sense of complex natural scenes. Dr. Stringers laboratory houses a team of theoreticians, who are developing computer models of a range of different aspects of brain function. Simon's lab is investigating the neural and synaptic dynamics that underpin brain function. An important matter here is the The feature-binding problem which concerns how the visual system represents the hierarchical relationships between features. the visual system must represent hierarchical binding relations across the entire visual field at every spatial scale and level in the hierarchy of visual primitives.</p>\n<p><br></p>\n<p>We discuss the emergence of self-organised behaviour, complex information processing, invariant sensory representations and hierarchical feature binding which emerges when you build biologically plausible neural networks with temporal spiking dynamics.&nbsp;</p>\n<p><br></p>\n<p><br></p>\n<p>00:00:09 Tim Intro&nbsp;</p>\n<p>00:09:31 Show kickoff&nbsp;</p>\n<p>00:14:37 Hierarchical Feature binding and timing of action potentials&nbsp;</p>\n<p>00:30:16 Hebb to Spike-timing-dependent plasticity (STDP)&nbsp;</p>\n<p>00:35:27 Encoding of shape primitives&nbsp;</p>\n<p>00:38:50 Is imagination working in the same place in the brain&nbsp;</p>\n<p>00:41:12 Compare to supervised CNNs&nbsp;</p>\n<p>00:45:59 Speech recognition, motor system, learning mazes&nbsp;</p>\n<p>00:49:28 How practical are these spiking NNs&nbsp;</p>\n<p>00:50:19 Why simulate the human brain&nbsp;</p>\n<p>00:52:46 How much computational power do you gain from differential timings&nbsp;</p>\n<p>00:55:08 Adversarial inputs&nbsp;</p>\n<p>00:59:41 Generative / causal component needed?&nbsp;</p>\n<p>01:01:46 Modalities of processing i.e. language&nbsp;</p>\n<p>01:03:42 Understanding&nbsp;</p>\n<p>01:04:37 Human hardware&nbsp;</p>\n<p>01:06:19 Roadmap of NNs?&nbsp;</p>\n<p>01:10:36 Intepretability methods for these new models&nbsp;</p>\n<p>01:13:03 Won't GPT just scale and do this anyway?&nbsp;</p>\n<p>01:15:51 What about trace learning and transformation learning&nbsp;</p>\n<p>01:18:50 Categories of invariance&nbsp;</p>\n<p>01:19:47 Biological plausibility&nbsp;</p>\n<p><br></p>\n<p>https://www.youtube.com/watch?v=aisgNLypUKs</p>\n",
    "EnclosureUrl": "https://anchor.fm/s/1e4a0eac/podcast/play/26169195/https%3A%2F%2Fd3ctxlq1ktw2nl.cloudfront.net%2Fstaging%2F2021-1-3%2Fd9a6bd7b-ccd6-0588-e57a-340dcc59fd46.mp3"
}